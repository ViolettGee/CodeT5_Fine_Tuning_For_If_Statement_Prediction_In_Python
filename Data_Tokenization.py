#file tokenizes the preprocessed data

#input columns: flattend/masked method, target_block
#output columns: tokenized_method, embeded_method, tokenized_target, embeded_target

#import necessary libraries

#function tokenizing a code section

#function creating a row in the data frame

#main section of code iterating through data

#initialize dataframes for data set
#initialize file input iterator object

#initialize output dataframes for data set

#initialize pre-trained tokenizer and embeddings

#create progress bar

    #iterate through input files

        #iterate through rows in input files

            #tokenize the method data

            #tokenize the target data

            #initialize output row 

            #update training output
            #update testing output
            #update validating output

            #increment progress bar

#write each output dataframe to a new csv