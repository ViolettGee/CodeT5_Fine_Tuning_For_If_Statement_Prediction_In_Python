#purpose to tokenize the files

#input: flattened/masked method, target_block
#output: tokenized_method, tokenized_target

#import necessary libraries

#function to tokenize code section

#function to add row to output

#initialize tokenizer

#initialize data sets

#initialize output data frames

#create progress bar

    #iterate through each data frame

        #iterate through each row of current data frame

            #call the function for tokenizing the method

            #call the function for tokenizing the target

            #initialize the output row

            #update training data

            #update test data

            #update validation data

            #increment progress bar

#write each data frame to a new csv