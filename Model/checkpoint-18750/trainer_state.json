{
  "best_global_step": 18750,
  "best_metric": 0.08125832676887512,
  "best_model_checkpoint": "Model/checkpoint-18750",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 18750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08,
      "grad_norm": 0.005104446783661842,
      "learning_rate": 0.048669333333333335,
      "loss": 0.2539,
      "step": 500
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.01230989396572113,
      "learning_rate": 0.047336,
      "loss": 0.1055,
      "step": 1000
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.00497783487662673,
      "learning_rate": 0.046002666666666664,
      "loss": 0.1376,
      "step": 1500
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.007544833235442638,
      "learning_rate": 0.04466933333333334,
      "loss": 0.1073,
      "step": 2000
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.005829162895679474,
      "learning_rate": 0.043336000000000006,
      "loss": 0.1105,
      "step": 2500
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.003641874296590686,
      "learning_rate": 0.04200266666666667,
      "loss": 0.108,
      "step": 3000
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.007846653461456299,
      "learning_rate": 0.040669333333333335,
      "loss": 0.1061,
      "step": 3500
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.007415806408971548,
      "learning_rate": 0.039336,
      "loss": 0.1017,
      "step": 4000
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.0054318783804774284,
      "learning_rate": 0.03800266666666667,
      "loss": 0.0961,
      "step": 4500
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.0049354201182723045,
      "learning_rate": 0.03666933333333333,
      "loss": 0.0984,
      "step": 5000
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.011633224785327911,
      "learning_rate": 0.035336,
      "loss": 0.0975,
      "step": 5500
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.009005188010632992,
      "learning_rate": 0.03400266666666667,
      "loss": 0.0923,
      "step": 6000
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.09012843668460846,
      "eval_runtime": 32.2069,
      "eval_samples_per_second": 155.246,
      "eval_steps_per_second": 19.406,
      "step": 6250
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.014368405565619469,
      "learning_rate": 0.032669333333333335,
      "loss": 0.0925,
      "step": 6500
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.00504873413592577,
      "learning_rate": 0.031336,
      "loss": 0.0924,
      "step": 7000
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.012154337018728256,
      "learning_rate": 0.030002666666666667,
      "loss": 0.0962,
      "step": 7500
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.014815394766628742,
      "learning_rate": 0.02866933333333334,
      "loss": 0.0963,
      "step": 8000
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.003926008008420467,
      "learning_rate": 0.027336,
      "loss": 0.0943,
      "step": 8500
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.007698437198996544,
      "learning_rate": 0.02600266666666667,
      "loss": 0.0936,
      "step": 9000
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.008530274964869022,
      "learning_rate": 0.024669333333333335,
      "loss": 0.091,
      "step": 9500
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.011152058839797974,
      "learning_rate": 0.023336000000000003,
      "loss": 0.0934,
      "step": 10000
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.008226136676967144,
      "learning_rate": 0.02200266666666667,
      "loss": 0.0912,
      "step": 10500
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.005843108519911766,
      "learning_rate": 0.020669333333333335,
      "loss": 0.0888,
      "step": 11000
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.017526226118206978,
      "learning_rate": 0.019336000000000002,
      "loss": 0.0926,
      "step": 11500
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.004552541766315699,
      "learning_rate": 0.018002666666666667,
      "loss": 0.0899,
      "step": 12000
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.0043572490103542805,
      "learning_rate": 0.016669333333333335,
      "loss": 0.0897,
      "step": 12500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.08670367300510406,
      "eval_runtime": 32.1982,
      "eval_samples_per_second": 155.288,
      "eval_steps_per_second": 19.411,
      "step": 12500
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.004033925477415323,
      "learning_rate": 0.015336,
      "loss": 0.089,
      "step": 13000
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.00458620535209775,
      "learning_rate": 0.014002666666666667,
      "loss": 0.0891,
      "step": 13500
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.007617405615746975,
      "learning_rate": 0.012669333333333333,
      "loss": 0.0894,
      "step": 14000
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.00975595973432064,
      "learning_rate": 0.011336,
      "loss": 0.0884,
      "step": 14500
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.008876432664692402,
      "learning_rate": 0.010002666666666667,
      "loss": 0.0878,
      "step": 15000
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.029541291296482086,
      "learning_rate": 0.008669333333333333,
      "loss": 0.0862,
      "step": 15500
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.026777150109410286,
      "learning_rate": 0.007336,
      "loss": 0.0884,
      "step": 16000
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.004502316005527973,
      "learning_rate": 0.006002666666666667,
      "loss": 0.0858,
      "step": 16500
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.0035629980266094208,
      "learning_rate": 0.0046693333333333335,
      "loss": 0.085,
      "step": 17000
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.004677214194089174,
      "learning_rate": 0.0033360000000000004,
      "loss": 0.0866,
      "step": 17500
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.014350991696119308,
      "learning_rate": 0.002002666666666667,
      "loss": 0.0858,
      "step": 18000
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.006183113437145948,
      "learning_rate": 0.0006693333333333334,
      "loss": 0.0853,
      "step": 18500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.08125832676887512,
      "eval_runtime": 32.1987,
      "eval_samples_per_second": 155.286,
      "eval_steps_per_second": 19.411,
      "step": 18750
    }
  ],
  "logging_steps": 500,
  "max_steps": 18750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 1,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.03012702208e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
