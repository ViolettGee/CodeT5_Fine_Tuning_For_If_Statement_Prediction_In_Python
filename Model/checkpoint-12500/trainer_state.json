{
  "best_global_step": 12500,
  "best_metric": 0.08670367300510406,
  "best_model_checkpoint": "Model/checkpoint-12500",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 12500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08,
      "grad_norm": 0.005104446783661842,
      "learning_rate": 0.048669333333333335,
      "loss": 0.2539,
      "step": 500
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.01230989396572113,
      "learning_rate": 0.047336,
      "loss": 0.1055,
      "step": 1000
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.00497783487662673,
      "learning_rate": 0.046002666666666664,
      "loss": 0.1376,
      "step": 1500
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.007544833235442638,
      "learning_rate": 0.04466933333333334,
      "loss": 0.1073,
      "step": 2000
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.005829162895679474,
      "learning_rate": 0.043336000000000006,
      "loss": 0.1105,
      "step": 2500
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.003641874296590686,
      "learning_rate": 0.04200266666666667,
      "loss": 0.108,
      "step": 3000
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.007846653461456299,
      "learning_rate": 0.040669333333333335,
      "loss": 0.1061,
      "step": 3500
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.007415806408971548,
      "learning_rate": 0.039336,
      "loss": 0.1017,
      "step": 4000
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.0054318783804774284,
      "learning_rate": 0.03800266666666667,
      "loss": 0.0961,
      "step": 4500
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.0049354201182723045,
      "learning_rate": 0.03666933333333333,
      "loss": 0.0984,
      "step": 5000
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.011633224785327911,
      "learning_rate": 0.035336,
      "loss": 0.0975,
      "step": 5500
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.009005188010632992,
      "learning_rate": 0.03400266666666667,
      "loss": 0.0923,
      "step": 6000
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.09012843668460846,
      "eval_runtime": 32.2069,
      "eval_samples_per_second": 155.246,
      "eval_steps_per_second": 19.406,
      "step": 6250
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.014368405565619469,
      "learning_rate": 0.032669333333333335,
      "loss": 0.0925,
      "step": 6500
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.00504873413592577,
      "learning_rate": 0.031336,
      "loss": 0.0924,
      "step": 7000
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.012154337018728256,
      "learning_rate": 0.030002666666666667,
      "loss": 0.0962,
      "step": 7500
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.014815394766628742,
      "learning_rate": 0.02866933333333334,
      "loss": 0.0963,
      "step": 8000
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.003926008008420467,
      "learning_rate": 0.027336,
      "loss": 0.0943,
      "step": 8500
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.007698437198996544,
      "learning_rate": 0.02600266666666667,
      "loss": 0.0936,
      "step": 9000
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.008530274964869022,
      "learning_rate": 0.024669333333333335,
      "loss": 0.091,
      "step": 9500
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.011152058839797974,
      "learning_rate": 0.023336000000000003,
      "loss": 0.0934,
      "step": 10000
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.008226136676967144,
      "learning_rate": 0.02200266666666667,
      "loss": 0.0912,
      "step": 10500
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.005843108519911766,
      "learning_rate": 0.020669333333333335,
      "loss": 0.0888,
      "step": 11000
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.017526226118206978,
      "learning_rate": 0.019336000000000002,
      "loss": 0.0926,
      "step": 11500
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.004552541766315699,
      "learning_rate": 0.018002666666666667,
      "loss": 0.0899,
      "step": 12000
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.0043572490103542805,
      "learning_rate": 0.016669333333333335,
      "loss": 0.0897,
      "step": 12500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.08670367300510406,
      "eval_runtime": 32.1982,
      "eval_samples_per_second": 155.288,
      "eval_steps_per_second": 19.411,
      "step": 12500
    }
  ],
  "logging_steps": 500,
  "max_steps": 18750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 1,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.35341801472e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
